<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>AI Coding on hgye&#39;s notes</title>
    <link>https://hgye.github.io/categories/ai-coding/</link>
    <description>Recent content in AI Coding on hgye&#39;s notes</description>
    <generator>Hugo -- 0.152.2</generator>
    <language>en-us</language>
    <copyright>2020 - 2025 hgye&amp;rsquo;s notes</copyright>
    <lastBuildDate>Mon, 15 Dec 2025 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://hgye.github.io/categories/ai-coding/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[AI coding] subagents(1)</title>
      <link>https://hgye.github.io/p/ai-coding-subagents1/</link>
      <pubDate>Mon, 08 Dec 2025 00:00:00 +0000</pubDate>
      <guid>https://hgye.github.io/p/ai-coding-subagents1/</guid>
      <description>&lt;p&gt;边思考边干，交织思维链，委托delegation（AI委派），这几个术语其实都是说一件事情&lt;/p&gt;
&lt;p&gt;GPT-5是省钱也好，降智也好，Opus当然也在降智（如果说4是偷偷降智还被喷，那么4.5就是公开说速度与效率的平衡），其实这些也都和subagents有着某种内在的联系。&lt;/p&gt;
&lt;p&gt;AI coding当然好，但是&amp;hellip;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;AI生成的code太过冗余和繁复了，想要理解和维护的代价相当大&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;更糟糕的是无法嵌入现有的项目的风格和设计&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;还有很多时候它只是别处心抒，绕道而言，完全不考虑现有的东西&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;他会忘记之前prompt给他的提示建议和限制，甚至于tool也需要再调用一遍&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;最可怕的是重启session，需要一条条的手工重建context，那么是重建，依然和丢掉的那一个不能比，不好用&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;所有这一切都是因为上下文吗，200K的context，你需要不断的compact history&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;半年多前claude code出世带来的震撼就是工具调用，尤其是shell调用的能力，带来了所谓的agentic的落地和想象，但是实际上agent的全委托依然不可能。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;mcp固然赋予了LLM工具调用的能力，但是你不能启用太多，据说超过10个就原地爆炸了，每启用一个就。。。默默的会占用一堆上下文（context里面的token）&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;怎么办呢？上一次遗留的问题自然是继续解决，subagents依然是Antropic提出来的&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;mcp解决和外部交互的问题，但是context上下文长度还是没有变，mcp的核心能力就是自然语言来理解应该什么时候调用外部工具，实际上就是自然语言理解的能力来处理输入&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;自然而然，就可以把调用外部工具变成调用新的LLM，新的LLM（subagent子代理）再去调用工具。这里的核心能j就是，NLP处理输入input&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;因为有了subagent，context当然是可以扩展的，context越大，越难遗忘或者越能保持一致性，这么说是不是。。。至少解决了一部分问题？&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;把mcp变成subagent，就是AI委派，但是subagent怎么划分和设计，比如git agent，jira restful agent etc，似乎目前没有看到一个hub（mcp可以直接install了），subagent不知道有没有&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;各家对于subagent的支持，cursorUI上直接有，claude支持agents命令，和.claude/agnets/&lt;em&gt;, copilot类似需要建立.github/agents/&lt;/em&gt;.md，UI上没有&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;进一步，subagent是不是让你想到了MoE，是的，专家门控网络，每次激活一个专家，一个sub network，但是，没有并发，但是结构依然非常类似，非常具有曼德布罗特Mandelbrot，分型的特性。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;GPT5.1和opus 4.5不约而同的走向了速度与开销的平衡，不是需要一个全能的模型，而是需要千亿个agents并发调用，orchestra合奏的美妙&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;千亿个agents如何协调？下一步是什么？deepseek 3.2 math说的很明确，RL放在过程，而不仅仅是结果了（这个和RL其实是有点违背，RL只讲结果才对）&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;deepseek 3.2标准版两个model，一个探索subagents，一个全能全知，但是这依然是GPT5.1和Opus 4.5之后很久很久的，闭源model领先的幅度越来越大&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;其实所有的复杂系统的调控，比如基因网络，都有一些超级节点，比如hox系列的foxp2，还有癌症里面p53，依稀都是要控制如何调用&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</description>
    </item>
  </channel>
</rss>
